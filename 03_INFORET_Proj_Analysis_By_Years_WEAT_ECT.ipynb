{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFORMATION RETRIEVAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gender stereotypes in parliamentary speeches\n",
    "\n",
    "In word embedding models, each word is assigned to a high-dimensional vector such that the geometry of the vectors captures semantic relations between the words – e.g. vectors being closer together has been shown to correspond to more similar words. Recent works in machine learning demonstrate that word embeddings also capture common stereotypes, as these stereotypes are likely to be present, even if subtly, in the large corpora of training texts. These stereotypes are automatically learned by the embedding algorithm and could be problematic in many context if the embedding is then used for sensitive applications such as search rankings, product recommendations, or translations. An important direction of research is on developing algorithms to debias the word embeddings.\n",
    "\n",
    "This project aims to use the word embeddings to study historical trends – specifically trends in the gender and ethnic stereotypes in the Italian parliamentary speeches from 1948 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from INFORET_project import load_embed_model\n",
    "# import matplotlib.pylab as plt\n",
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from INFORET_project import YEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1948_1968', '1968_1985', '1985_2000', '2000_2020']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_embed_model(YEARS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_embed_model(YEARS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_embed_model(YEARS[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ANALYSIS OF GENDER STEREOTYPES BY YEARSmodel = load_embed_model(YEARS[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ANALYSIS OF GENDER STEREOTYPES BY YEARS (WEAT, ECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) WEAT and ECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from INFORET_project import WEAT\n",
    "from INFORET_project.data import gendered_neutral_words\n",
    "from INFORET_project import PAIRS_WORDS_GROUP, WORDS_GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'career vs. family',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': -0.752927340567112,\n",
       " 'd': -1.6041145,\n",
       " 'p': 0.9989177489177489,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEAT(model.wv, \n",
    "     first_target={'name':'career', 'words': gendered_neutral_words['career']},\n",
    "     second_target={'name':'family', 'words': gendered_neutral_words['family']},\n",
    "     first_attribute={'name':'donna', 'words': gendered_neutral_words['female']},\n",
    "     second_attribute={'name':'uomo', 'words': gendered_neutral_words['male']}\n",
    ")\n",
    "\n",
    "# WEAT result (score, size effect, Nt, Na and p-value)\n",
    "# score: z-score. result of the test statistic\n",
    "# size effect: intensity of the effect, how much the 2 samples are separated\n",
    "# p-value: The null hypothesis is that there is no difference between the two sets of target words in \n",
    "#terms of their relative similarity to the two sets of attribute words.\n",
    "# Nt: dimension of target (6x2: 6 words for 2 targets)\n",
    "# Na: dimension of attributes (8x2: 8 words for 2 attributes)\n",
    "\n",
    "# low p-value, so H0 rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'male_stereotypes vs. female_stereotypes',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': -0.24709320068359375,\n",
       " 'd': -0.95323783,\n",
       " 'p': 0.9557109557109557,\n",
       " 'Nt': '7x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEAT(model.wv, \n",
    "     first_target={'name':'male_stereotypes', 'words': gendered_neutral_words['male_stereotypes']},\n",
    "     second_target={'name':'female_stereotypes', 'words': gendered_neutral_words['female_stereotypes']},\n",
    "     first_attribute={'name':'donna', 'words': gendered_neutral_words['female']},\n",
    "     second_attribute={'name':'uomo', 'words': gendered_neutral_words['male']}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_weat_by_year(year):\n",
    "    \n",
    "    model = load_embed_model(year)\n",
    "    \n",
    "    for pair in PAIRS_WORDS_GROUP:\n",
    "        w1,w2 = pair\n",
    "        \n",
    "        display(\n",
    "            WEAT(model.wv, \n",
    "         first_target={'name':f'{w1}', 'words': gendered_neutral_words[w1]},\n",
    "         second_target={'name':f'{w2}', 'words': gendered_neutral_words[w2]},\n",
    "         first_attribute={'name':'donna', 'words': gendered_neutral_words['female']},\n",
    "         second_attribute={'name':'uomo', 'words': gendered_neutral_words['male']})\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'family vs. career',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.752927340567112,\n",
       " 'd': 1.6041145,\n",
       " 'p': 0.0,\n",
       " 'Nt': '6x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'rage vs. kindness',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.03358858823776245,\n",
       " 'd': 0.17383628,\n",
       " 'p': 0.38852813852813856,\n",
       " 'Nt': '6x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'intelligence vs. dumbness',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': -0.30264808237552643,\n",
       " 'd': -1.2351941,\n",
       " 'p': 0.9682539682539683,\n",
       " 'Nt': '5x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'active vs. passive',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': -0.19418787956237793,\n",
       " 'd': -1.7242286,\n",
       " 'p': 0.95,\n",
       " 'Nt': '3x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'female_stereotypes vs. male_stereotypes',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.24709320068359375,\n",
       " 'd': 0.9532377,\n",
       " 'p': 0.043997668997669,\n",
       " 'Nt': '13x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_weat_by_year(YEARS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: a large p-value means that we accept H0, so that the 2 target groups have no statistical\n",
    "#difference when compared to the genders. since the control group contains gendered words, having a \n",
    "#large p-value means that the group to test has a strong gender component, so it is biased. \n",
    "# thus, the groups will be ranked from the highest to the lowest p-value\n",
    "\n",
    "def show_weat_by_year_control(year, verbose=True):\n",
    "    \n",
    "    model = load_embed_model(year)\n",
    "    \n",
    "    weat_top_biased = []\n",
    "    \n",
    "    for w in WORDS_GROUP:\n",
    "        \n",
    "        weat = WEAT(model.wv, \n",
    "                first_target={'name':'gendered_words', 'words': gendered_neutral_words['gendered_words']},\n",
    "                second_target={'name':f'{w}', 'words': gendered_neutral_words[w]},\n",
    "                first_attribute={'name':'donna', 'words': gendered_neutral_words['female']},\n",
    "                second_attribute={'name':'uomo', 'words': gendered_neutral_words['male']})\n",
    "            \n",
    "        weat_top_biased.append( (w, weat['p']) )\n",
    "\n",
    "        if verbose:\n",
    "            display(weat)\n",
    "        \n",
    "    return sorted(weat_top_biased, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. adj_appearence',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.4247361421585083,\n",
       " 'd': 0.6344866,\n",
       " 'p': 0.08651410508995648,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. family',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': -0.1948731690645218,\n",
       " 'd': -0.44564193,\n",
       " 'p': 0.7608225108225108,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. career',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 1.1725627165287733,\n",
       " 'd': 1.3028558,\n",
       " 'p': 0.0009796704843144472,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. rage',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.322650209069252,\n",
       " 'd': 0.7504526,\n",
       " 'p': 0.14502164502164502,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. kindness',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.5006775185465813,\n",
       " 'd': 1.0376654,\n",
       " 'p': 0.04004329004329004,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. intelligence',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.5428943261504173,\n",
       " 'd': 1.2084794,\n",
       " 'p': 0.01984126984126984,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. dumbness',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.16958500444889069,\n",
       " 'd': 0.44721156,\n",
       " 'p': 0.25396825396825395,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. active',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.27020979672670364,\n",
       " 'd': 1.0259635,\n",
       " 'p': 0.1,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. passive',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.22756554186344147,\n",
       " 'd': 0.59813553,\n",
       " 'p': 0.1984126984126984,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. gendered_words',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.0,\n",
       " 'd': 0.0,\n",
       " 'p': 0.4972287774145359,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. female_stereotypes',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.629240594804287,\n",
       " 'd': 0.86994576,\n",
       " 'p': 0.02830760570698651,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'gendered_words vs. male_stereotypes',\n",
       " 'Attrib. words': 'donna vs. uomo',\n",
       " 's': 0.6358938738703728,\n",
       " 'd': 1.0684642,\n",
       " 'p': 0.030011655011655012,\n",
       " 'Nt': '10x2',\n",
       " 'Na': '3x2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = show_weat_by_year_control(YEARS[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04af5acd48844183a97631dee6ecb81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing years'), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "WEAT_group_bias = defaultdict(dict)\n",
    "\n",
    "for year in tqdm(YEARS,\n",
    "                 desc='Passing years'):\n",
    "    WEAT_group_bias[year] = show_weat_by_year_control(year, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store data\n",
    "%store -r results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    results[f'WEAT_{year}'] = [group[0] for group in WEAT_group_bias[year]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results' (DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analogies_bias_1948_1968</th>\n",
       "      <th>analogies_bias_avg_gender_1948_1968</th>\n",
       "      <th>ECT_1948_1968</th>\n",
       "      <th>WEAT_1948_1968</th>\n",
       "      <th>analogies_bias_1968_1985</th>\n",
       "      <th>analogies_bias_avg_gender_1968_1985</th>\n",
       "      <th>ECT_1968_1985</th>\n",
       "      <th>WEAT_1968_1985</th>\n",
       "      <th>analogies_bias_1985_2000</th>\n",
       "      <th>analogies_bias_avg_gender_1985_2000</th>\n",
       "      <th>ECT_1985_2000</th>\n",
       "      <th>WEAT_1985_2000</th>\n",
       "      <th>analogies_bias_2000_2020</th>\n",
       "      <th>analogies_bias_avg_gender_2000_2020</th>\n",
       "      <th>ECT_2000_2020</th>\n",
       "      <th>WEAT_2000_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>family</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>family</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>active</td>\n",
       "      <td>family</td>\n",
       "      <td>active</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>passive</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>gendered_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>passive</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>career</td>\n",
       "      <td>passive</td>\n",
       "      <td>family</td>\n",
       "      <td>rage</td>\n",
       "      <td>passive</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>family</td>\n",
       "      <td>rage</td>\n",
       "      <td>passive</td>\n",
       "      <td>kindness</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>passive</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>passive</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>rage</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>dumbness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kindness</td>\n",
       "      <td>career</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>rage</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>passive</td>\n",
       "      <td>rage</td>\n",
       "      <td>rage</td>\n",
       "      <td>kindness</td>\n",
       "      <td>family</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>career</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>rage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>passive</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>family</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>active</td>\n",
       "      <td>kindness</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>rage</td>\n",
       "      <td>rage</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>family</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>kindness</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>career</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>active</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>kindness</td>\n",
       "      <td>kindness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>female_stereotypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>passive</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>kindness</td>\n",
       "      <td>kindness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>adj_appearence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>kindness</td>\n",
       "      <td>kindness</td>\n",
       "      <td>career</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>passive</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>kindness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rage</td>\n",
       "      <td>rage</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>rage</td>\n",
       "      <td>career</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>passive</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>rage</td>\n",
       "      <td>career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dumbness</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>active</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>rage</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>rage</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>career</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>rage</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>career</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>career</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>active</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analogies_bias_1948_1968 analogies_bias_avg_gender_1948_1968  \\\n",
       "0            gendered_words                      gendered_words   \n",
       "1                    active                        intelligence   \n",
       "2            adj_appearence                      adj_appearence   \n",
       "3          male_stereotypes                              family   \n",
       "4                  kindness                              career   \n",
       "5                   passive                    male_stereotypes   \n",
       "6                    family                             passive   \n",
       "7              intelligence                  female_stereotypes   \n",
       "8        female_stereotypes                            kindness   \n",
       "9                      rage                                rage   \n",
       "10                 dumbness                            dumbness   \n",
       "11                   career                              active   \n",
       "\n",
       "         ECT_1948_1968      WEAT_1948_1968 analogies_bias_1968_1985  \\\n",
       "0       adj_appearence              family           gendered_words   \n",
       "1       gendered_words      gendered_words                   active   \n",
       "2             dumbness            dumbness                  passive   \n",
       "3                 rage             passive                 kindness   \n",
       "4   female_stereotypes                rage             intelligence   \n",
       "5               family      adj_appearence           adj_appearence   \n",
       "6               career            kindness                   family   \n",
       "7              passive  female_stereotypes         male_stereotypes   \n",
       "8             kindness              career       female_stereotypes   \n",
       "9         intelligence    male_stereotypes                     rage   \n",
       "10              active        intelligence                   career   \n",
       "11    male_stereotypes              active                 dumbness   \n",
       "\n",
       "   analogies_bias_avg_gender_1968_1985       ECT_1968_1985  \\\n",
       "0                       gendered_words              family   \n",
       "1                               family              active   \n",
       "2                       adj_appearence  female_stereotypes   \n",
       "3                             dumbness        intelligence   \n",
       "4                         intelligence             passive   \n",
       "5                   female_stereotypes      adj_appearence   \n",
       "6                             kindness              career   \n",
       "7                     male_stereotypes            kindness   \n",
       "8                              passive            dumbness   \n",
       "9                               career      gendered_words   \n",
       "10                              active                rage   \n",
       "11                                rage    male_stereotypes   \n",
       "\n",
       "        WEAT_1968_1985 analogies_bias_1985_2000  \\\n",
       "0               family           gendered_words   \n",
       "1       gendered_words                   family   \n",
       "2             dumbness                  passive   \n",
       "3              passive           adj_appearence   \n",
       "4                 rage                     rage   \n",
       "5               active                 kindness   \n",
       "6       adj_appearence                   active   \n",
       "7             kindness       female_stereotypes   \n",
       "8     male_stereotypes                   career   \n",
       "9   female_stereotypes         male_stereotypes   \n",
       "10        intelligence             intelligence   \n",
       "11              career                 dumbness   \n",
       "\n",
       "   analogies_bias_avg_gender_1985_2000       ECT_1985_2000  \\\n",
       "0                       gendered_words      gendered_words   \n",
       "1                               family            kindness   \n",
       "2                               career              career   \n",
       "3                              passive  female_stereotypes   \n",
       "4                             kindness              family   \n",
       "5                       adj_appearence                rage   \n",
       "6                   female_stereotypes        intelligence   \n",
       "7                         intelligence      adj_appearence   \n",
       "8                               active            dumbness   \n",
       "9                             dumbness             passive   \n",
       "10                                rage    male_stereotypes   \n",
       "11                    male_stereotypes              active   \n",
       "\n",
       "        WEAT_1985_2000 analogies_bias_2000_2020  \\\n",
       "0               family           gendered_words   \n",
       "1       gendered_words                  passive   \n",
       "2              passive                   family   \n",
       "3               active                     rage   \n",
       "4             dumbness             intelligence   \n",
       "5                 rage           adj_appearence   \n",
       "6             kindness                 kindness   \n",
       "7     male_stereotypes         male_stereotypes   \n",
       "8   female_stereotypes                   active   \n",
       "9         intelligence       female_stereotypes   \n",
       "10      adj_appearence                   career   \n",
       "11              career                 dumbness   \n",
       "\n",
       "   analogies_bias_avg_gender_2000_2020       ECT_2000_2020      WEAT_2000_2020  \n",
       "0                       gendered_words      gendered_words              family  \n",
       "1                               family            kindness      gendered_words  \n",
       "2                                 rage             passive             passive  \n",
       "3                              passive              career            dumbness  \n",
       "4                               career        intelligence                rage  \n",
       "5                             dumbness              family            kindness  \n",
       "6                   female_stereotypes              active  female_stereotypes  \n",
       "7                     male_stereotypes    male_stereotypes      adj_appearence  \n",
       "8                             kindness  female_stereotypes    male_stereotypes  \n",
       "9                         intelligence                rage              career  \n",
       "10                      adj_appearence      adj_appearence        intelligence  \n",
       "11                              active            dumbness              active  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from INFORET_project.utils import fast_cosine_sim, calculate_avg_vector, to_list\n",
    "from INFORET_project import ECT\n",
    "from INFORET_project import WORDS_GROUP\n",
    "from INFORET_project.data import gendered_neutral_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECT for words: ['famiglia', 'figlio', 'matrimonio', 'genitore', 'bambino', 'accudire']\n",
      "\n",
      "Spearman correlation has value 0.7714 with p-value 0.0724\n",
      "High correlation --> Low bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ect = ECT(model.wv, gendered_neutral_words['female'], gendered_neutral_words['male'])\n",
    "\n",
    "spearman_corr = ect.get_bias(neutral_words = gendered_neutral_words['family'],\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of 'bambino' to 'female' is 0.5360, to 'male' is 0.4293\n",
      "Cosine similarity of 'genitore' to 'female' is 0.3743, to 'male' is 0.4375\n",
      "Cosine similarity of 'accudire' to 'female' is 0.3432, to 'male' is 0.3072\n",
      "Cosine similarity of 'figlio' to 'female' is 0.4409, to 'male' is 0.4577\n",
      "Cosine similarity of 'matrimonio' to 'female' is 0.3251, to 'male' is 0.3103\n",
      "Cosine similarity of 'famiglia' to 'female' is 0.3612, to 'male' is 0.3747\n"
     ]
    }
   ],
   "source": [
    "biased_words = ect.get_cosine_sim_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bambino', 0.536, 0.4293),\n",
       " ('genitore', 0.3743, 0.4375),\n",
       " ('accudire', 0.3432, 0.3072),\n",
       " ('figlio', 0.4409, 0.4577),\n",
       " ('matrimonio', 0.3251, 0.3103),\n",
       " ('famiglia', 0.3612, 0.3747)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECT for words: ['timido', 'passivo', 'insicuro', 'debole', 'silenzioso']\n",
      "\n",
      "Spearman correlation has value 0.9000 with p-value 0.0374\n",
      "High correlation --> Low bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ect = ECT(model.wv, gendered_neutral_words['female'], gendered_neutral_words['male'])\n",
    "\n",
    "spearman_corr = ect.get_bias(neutral_words = gendered_neutral_words['passive'],\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of 'debole' to 'female' is 0.1828, to 'male' is 0.2310\n",
      "Cosine similarity of 'passivo' to 'female' is 0.1363, to 'male' is 0.1141\n",
      "Cosine similarity of 'timido' to 'female' is 0.1614, to 'male' is 0.1810\n",
      "Cosine similarity of 'silenzioso' to 'female' is 0.2889, to 'male' is 0.2705\n",
      "Cosine similarity of 'insicuro' to 'female' is 0.2304, to 'male' is 0.2268\n"
     ]
    }
   ],
   "source": [
    "biased_words = ect.get_cosine_sim_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparazoone metodi diversi\n",
    "# ob funzioni: capire qnd parola legata a genere\n",
    "# fai ranking parole, se i metodi sono robusti.\n",
    "# studia intersezioni tra parole\n",
    "# fai manualmente liste di parole polarizzate e parole neutre, vedi\n",
    "# se i metodi le trovano nella posizione giusta.\n",
    "# applica debias e vedi differenze?\n",
    "# baseline: dividi i doc in 2 gruppi M,F e calcola misura di specificità di\n",
    "#parole (TFIDF, PMI) per vedere se sono caratteristiche.\n",
    "# i metodi fanno meglio? \n",
    "\n",
    "# correlazione tra stereotipi e numero di donne in aumento del parlamentoà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71ad6d9f8254794a35b6328b5c1a7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing models'), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25abf2f648d346cbb3c9299dce4e8873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing groups of words'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ff9fd34a1f4d00a144989d2cfc25cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing groups of words'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6134b8fe3f1b4dd5a224f67394766eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing groups of words'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb77ca227404ad38296b8bfe0cebe7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Passing groups of words'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ECT_group_bias = defaultdict(list)\n",
    "ECT_top_bias = defaultdict(lambda: defaultdict(OrderedDict))\n",
    "\n",
    "for year in tqdm(YEARS,\n",
    "                   desc='Passing models'\n",
    "                  ):\n",
    "    model = load_embed_model(year)\n",
    "    \n",
    "    g=[]\n",
    "    for group in tqdm(WORDS_GROUP,\n",
    "                        desc='Passing groups of words'\n",
    "                     ):\n",
    "        \n",
    "        ect = ECT(model.wv, gendered_neutral_words['female'], gendered_neutral_words['male'])\n",
    "        spearman_corr = ect.get_bias(neutral_words=gendered_neutral_words[group],\n",
    "                         verbose=False)\n",
    "        biased_words = ect.get_cosine_sim_words(verbose=False)\n",
    "    \n",
    "        g.append((group, spearman_corr))\n",
    "        ECT_top_bias[year][group] = biased_words\n",
    "        \n",
    "    ECT_group_bias[year] = sorted(g, key=lambda x: x[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ECT_top_bias' (OrderedDict)\n"
     ]
    }
   ],
   "source": [
    "ECT_top_bias = OrderedDict(ECT_top_bias)\n",
    "%store ECT_top_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adj_appearence', 0.29696969696969694),\n",
       " ('gendered_words', 0.5272727272727272),\n",
       " ('dumbness', 0.6),\n",
       " ('rage', 0.6571428571428573),\n",
       " ('female_stereotypes', 0.7197802197802198),\n",
       " ('family', 0.7714285714285715),\n",
       " ('career', 0.8424242424242423),\n",
       " ('passive', 0.8999999999999998),\n",
       " ('kindness', 0.942857142857143),\n",
       " ('intelligence', 0.9999999999999999),\n",
       " ('active', 1.0),\n",
       " ('male_stereotypes', 1.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('family', 0.08571428571428573),\n",
       " ('active', 0.5),\n",
       " ('female_stereotypes', 0.6758241758241759),\n",
       " ('intelligence', 0.7),\n",
       " ('passive', 0.7),\n",
       " ('adj_appearence', 0.709090909090909),\n",
       " ('career', 0.7696969696969697),\n",
       " ('kindness', 0.7714285714285715),\n",
       " ('dumbness', 0.7999999999999999),\n",
       " ('gendered_words', 0.8181818181818182),\n",
       " ('rage', 0.8857142857142858),\n",
       " ('male_stereotypes', 0.8928571428571429)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('gendered_words', 0.05454545454545454),\n",
       " ('kindness', 0.3714285714285715),\n",
       " ('career', 0.41818181818181815),\n",
       " ('female_stereotypes', 0.6538461538461539),\n",
       " ('family', 0.7714285714285715),\n",
       " ('rage', 0.7714285714285715),\n",
       " ('intelligence', 0.7999999999999999),\n",
       " ('adj_appearence', 0.8571428571428572),\n",
       " ('dumbness', 0.8999999999999998),\n",
       " ('passive', 0.8999999999999998),\n",
       " ('male_stereotypes', 0.9642857142857145),\n",
       " ('active', 1.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('gendered_words', -0.06666666666666665),\n",
       " ('kindness', 0.3714285714285715),\n",
       " ('passive', 0.39999999999999997),\n",
       " ('career', 0.41818181818181815),\n",
       " ('intelligence', 0.6),\n",
       " ('family', 0.7714285714285715),\n",
       " ('active', 0.7999999999999999),\n",
       " ('male_stereotypes', 0.8095238095238096),\n",
       " ('female_stereotypes', 0.8131868131868131),\n",
       " ('rage', 0.8857142857142858),\n",
       " ('adj_appearence', 0.9166666666666666),\n",
       " ('dumbness', 0.9999999999999999)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "    display(ECT_group_bias[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store data\n",
    "%store -r results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    results[f'ECT_{year}'] = [group[0] for group in ECT_group_bias[year]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results' (DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analogies_bias_1948_1968</th>\n",
       "      <th>analogies_bias_avg_gender_1948_1968</th>\n",
       "      <th>ECT_1948_1968</th>\n",
       "      <th>WEAT_1948_1968</th>\n",
       "      <th>analogies_bias_1968_1985</th>\n",
       "      <th>analogies_bias_avg_gender_1968_1985</th>\n",
       "      <th>ECT_1968_1985</th>\n",
       "      <th>WEAT_1968_1985</th>\n",
       "      <th>analogies_bias_1985_2000</th>\n",
       "      <th>analogies_bias_avg_gender_1985_2000</th>\n",
       "      <th>ECT_1985_2000</th>\n",
       "      <th>WEAT_1985_2000</th>\n",
       "      <th>analogies_bias_2000_2020</th>\n",
       "      <th>analogies_bias_avg_gender_2000_2020</th>\n",
       "      <th>ECT_2000_2020</th>\n",
       "      <th>WEAT_2000_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>family</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>passive</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>passive</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>family</td>\n",
       "      <td>rage</td>\n",
       "      <td>passive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>family</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindness</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>passive</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rage</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kindness</td>\n",
       "      <td>career</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>passive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rage</td>\n",
       "      <td>kindness</td>\n",
       "      <td>family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>career</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>passive</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindness</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>family</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>family</td>\n",
       "      <td>passive</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>family</td>\n",
       "      <td>kindness</td>\n",
       "      <td>career</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>passive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>kindness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>kindness</td>\n",
       "      <td>kindness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>passive</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>kindness</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rage</td>\n",
       "      <td>rage</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rage</td>\n",
       "      <td>career</td>\n",
       "      <td>gendered_words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>passive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female_stereotypes</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dumbness</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>rage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>rage</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>career</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>adj_appearence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>career</td>\n",
       "      <td>active</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>rage</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>male_stereotypes</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>active</td>\n",
       "      <td>dumbness</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analogies_bias_1948_1968 analogies_bias_avg_gender_1948_1968  \\\n",
       "0            gendered_words                      gendered_words   \n",
       "1                    active                        intelligence   \n",
       "2            adj_appearence                      adj_appearence   \n",
       "3          male_stereotypes                              family   \n",
       "4                  kindness                              career   \n",
       "5                   passive                    male_stereotypes   \n",
       "6                    family                             passive   \n",
       "7              intelligence                  female_stereotypes   \n",
       "8        female_stereotypes                            kindness   \n",
       "9                      rage                                rage   \n",
       "10                 dumbness                            dumbness   \n",
       "11                   career                              active   \n",
       "\n",
       "         ECT_1948_1968 WEAT_1948_1968 analogies_bias_1968_1985  \\\n",
       "0       adj_appearence            NaN           gendered_words   \n",
       "1       gendered_words            NaN                   active   \n",
       "2             dumbness            NaN                  passive   \n",
       "3                 rage            NaN                 kindness   \n",
       "4   female_stereotypes            NaN             intelligence   \n",
       "5               family            NaN           adj_appearence   \n",
       "6               career            NaN                   family   \n",
       "7              passive            NaN         male_stereotypes   \n",
       "8             kindness            NaN       female_stereotypes   \n",
       "9         intelligence            NaN                     rage   \n",
       "10              active            NaN                   career   \n",
       "11    male_stereotypes            NaN                 dumbness   \n",
       "\n",
       "   analogies_bias_avg_gender_1968_1985       ECT_1968_1985 WEAT_1968_1985  \\\n",
       "0                       gendered_words              family            NaN   \n",
       "1                               family              active            NaN   \n",
       "2                       adj_appearence  female_stereotypes            NaN   \n",
       "3                             dumbness        intelligence            NaN   \n",
       "4                         intelligence             passive            NaN   \n",
       "5                   female_stereotypes      adj_appearence            NaN   \n",
       "6                             kindness              career            NaN   \n",
       "7                     male_stereotypes            kindness            NaN   \n",
       "8                              passive            dumbness            NaN   \n",
       "9                               career      gendered_words            NaN   \n",
       "10                              active                rage            NaN   \n",
       "11                                rage    male_stereotypes            NaN   \n",
       "\n",
       "   analogies_bias_1985_2000 analogies_bias_avg_gender_1985_2000  \\\n",
       "0            gendered_words                      gendered_words   \n",
       "1                    family                              family   \n",
       "2                   passive                              career   \n",
       "3            adj_appearence                             passive   \n",
       "4                      rage                            kindness   \n",
       "5                  kindness                      adj_appearence   \n",
       "6                    active                  female_stereotypes   \n",
       "7        female_stereotypes                        intelligence   \n",
       "8                    career                              active   \n",
       "9          male_stereotypes                            dumbness   \n",
       "10             intelligence                                rage   \n",
       "11                 dumbness                    male_stereotypes   \n",
       "\n",
       "         ECT_1985_2000 WEAT_1985_2000 analogies_bias_2000_2020  \\\n",
       "0       gendered_words            NaN           gendered_words   \n",
       "1             kindness            NaN                  passive   \n",
       "2               career            NaN                   family   \n",
       "3   female_stereotypes            NaN                     rage   \n",
       "4               family            NaN             intelligence   \n",
       "5                 rage            NaN           adj_appearence   \n",
       "6         intelligence            NaN                 kindness   \n",
       "7       adj_appearence            NaN         male_stereotypes   \n",
       "8             dumbness            NaN                   active   \n",
       "9              passive            NaN       female_stereotypes   \n",
       "10    male_stereotypes            NaN                   career   \n",
       "11              active            NaN                 dumbness   \n",
       "\n",
       "   analogies_bias_avg_gender_2000_2020       ECT_2000_2020 WEAT_2000_2020  \n",
       "0                       gendered_words      gendered_words            NaN  \n",
       "1                               family            kindness            NaN  \n",
       "2                                 rage             passive            NaN  \n",
       "3                              passive              career            NaN  \n",
       "4                               career        intelligence            NaN  \n",
       "5                             dumbness              family            NaN  \n",
       "6                   female_stereotypes              active            NaN  \n",
       "7                     male_stereotypes    male_stereotypes            NaN  \n",
       "8                             kindness  female_stereotypes            NaN  \n",
       "9                         intelligence                rage            NaN  \n",
       "10                      adj_appearence      adj_appearence            NaN  \n",
       "11                              active            dumbness            NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
